{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d375d-6cc1-412e-9364-1244363b83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865e702d-db04-4b4a-bf3c-8f40487191db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e079a83b-fabe-4245-898b-7c7df6e01b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 70000\n",
    "batch_size = 128\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cab206c-afd9-4808-afe9-033786fd7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train,mnist_test = mnist_dataset['train'],mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7deeef-ba6a-44e1-a3b8-16bde14f11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255.\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c0f7e9-98c2-4277-b0b8-7b3746453102",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_val = mnist_train.map(scaler)\n",
    "scaled_test = mnist_test.map(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1d20d0-232f-4e40-8725-11ce3bd7a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_val_samples = tf.cast(num_val_samples,tf.int64)\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15d9860-1b3d-46a6-ac30-4a60cfdb5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train = scaled_train_val.shuffle(buffer_size)\n",
    "validation_data = scaled_train_val.take(num_val_samples)\n",
    "train_data = scaled_train_val.skip(num_val_samples)\n",
    "train_data = train_data.batch(batch_size)\n",
    "validation_data = validation_data.batch(num_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2eb229-8c7f-4642-a721-b5a4652b9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scaled_test.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be1eafd5-7316-4dbf-8c24-277d16edc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the numpy arrays from the validation data for the calculation of the Confusion Matrix\n",
    "for images, labels in validation_data:\n",
    "    images_val = images.numpy()\n",
    "    labels_val = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a048fda-d1db-47f9-a92f-a1d663afd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_model = tf.keras.Sequential([\n",
    "                                 tf.keras.layers.Conv2D(50,5,activation='relu',input_shape=(28,28,1)),\n",
    "                                 tf.keras.layers.MaxPooling2D(),\n",
    "                                 tf.keras.layers.Conv2D(50,3,activation='relu'),\n",
    "                                 tf.keras.layers.MaxPooling2D(),\n",
    "                                 tf.keras.layers.Flatten(),\n",
    "                                 tf.keras.layers.Dense(10)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba9c116-2783-423d-9e17-e35e14572712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "con_model.summary(line_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e085b9-d964-4cac-9b97-d3b528e5b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dea320e-fa6d-474c-bb3c-39f80a50acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_model.compile(optimizer='adam',loss=loss,metrics=['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='auto',min_delta=0,patience = 2,verbose=0,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f70ff8f-8fda-4136-b410-664d8311bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"Logs\\\\fit\\\\\" + \"run-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "632417ec-6d16-47ba-a68b-2cbc9361728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448f30ab-6cd6-4a0d-abda-19c77f79f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    \n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "    plt.close(figure)\n",
    "    \n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71d7109c-8ad7-468d-8557-793b93c8630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a file writer variable for logging purposes\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = con_model.predict(images_val)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(labels_val, test_pred)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm, class_names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8855eda-8004-45dd-8054-54390cfbd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the callbacks\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b675943-c073-450f-8472-039432bab4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 40s - loss: 0.0725 - accuracy: 0.9782 - val_loss: 0.0702 - val_accuracy: 0.9793 - 40s/epoch - 94ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 38s - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.0614 - val_accuracy: 0.9830 - 38s/epoch - 91ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 47s - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0567 - val_accuracy: 0.9847 - 47s/epoch - 112ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 46s - loss: 0.0352 - accuracy: 0.9895 - val_loss: 0.0540 - val_accuracy: 0.9855 - 46s/epoch - 109ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 45s - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.0514 - val_accuracy: 0.9863 - 45s/epoch - 107ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 46s - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0498 - val_accuracy: 0.9862 - 46s/epoch - 110ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 45s - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0480 - val_accuracy: 0.9867 - 45s/epoch - 108ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 46s - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0486 - val_accuracy: 0.9873 - 46s/epoch - 109ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 46s - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.0527 - val_accuracy: 0.9872 - 46s/epoch - 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e46257e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_model.fit(train_data,\n",
    "          epochs = num_epochs,\n",
    "          validation_data = validation_data,\n",
    "          verbose = 2,\n",
    "          callbacks = [early_stopping,tensorboard_callback,cm_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "518f46e1-5dd7-4890-9da9-b8b710914f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - accuracy: 0.9888\n",
      "Loss = 0.03 , accuracy = 98.88 %\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = con_model.evaluate(test_data)\n",
    "print(f\"Loss = {round(test_loss,2)} , accuracy = {round(test_accuracy*100,2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8939ea-cf32-47cc-8a94-34762320348f",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c25e273-3451-4ca8-baf4-dea01d271ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11400), started 0:51:49 ago. (Use '!kill 11400' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b730d757b821b0c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b730d757b821b0c0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdfbca-a51f-40ef-9f30-c6c655c02c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
